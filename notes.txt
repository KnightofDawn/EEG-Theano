## Follow notes in : 
http://blog.mdda.net/oss/2014/10/13/ipython-on-fedora/
http://blog.mdda.net/oss/2014/10/19/pygtk-for-virtualenv/
http://blog.mdda.net/oss/2014/10/20/directories-in-ipython/

Additionally : hickle
sudo yum install hdf5-devel
(env) pip install hickle


ipython notebook
# and open a browser to http://localhost:8888/
%matplotlib inline

mkdir -p data/feat/{Dog_1,Dog_2,Dog_3,Dog_4,Dog_5,Patient_1,Patient_2}
## NO mkdir -p data/model/{Dog_1,Dog_2,Dog_3,Dog_4,Dog_5,Patient_1,Patient_2}

cd data/orig
tar -xzf Dog1.tar.gz
tar -xzf Dog2.tar.gz
tar -xzf Dog3.tar.gz

tar -xzf Dog4.tar.gz
tar -xzf Dog5.tar.gz
tar -xzf Patient1.tar.gz
tar -xzf Patient2.tar.gz
cd ../..

## Create the loader csv
python src/survey.py --patient Dog_1
python src/survey.py --patient Dog_2

python src/survey.py --patient Dog_3
python src/survey.py --patient Dog_4
python src/survey.py --patient Dog_5
python src/survey.py --patient Patient_1
python src/survey.py --patient Patient_2


## Preprocess all the training and test files into features 
#  Dog_2     :: (~0.5sec each => 1543 in 16min)

python src/preprocess.py --patient Dog_2 --fft 1 --scale 0 --train 0
python src/preprocess.py --patient Dog_2 --fft 0 --scale 1 --train 1 
python src/preprocess.py --patient Dog_2 --fft 0 --scale 1 --train 0 

#  Patient_2 :: (~ 25sec each =>  211 in 89min)


# CPU verison : 3m10s
python src/contractive_autoencode.py --patient Dog_2 --layer 1 --train 1
python src/contractive_autoencode.py --patient Dog_2 --layer 1 --train 0



# GPU (OpenCL) version : NOT WORKING
THEANO_FLAGS=mode=FAST_RUN,device=opencl0:0,floatX=float32,exception_verbosity=high,optimizer=fast_compile  optirun --no-xorg python src/contractive_autoencode.py 



# Works to test loader :
python src/graph.py 

import sys
sys.path.append('../src')
import EEG

Data
  Dog   x 5 
    16 electrodes @ 400Hz
  Human x 2                            
    24 electrodes @ 5000Hz
    

ToDo : 
  2 stage training, where pre-ictal periods are split into 'active' and 'inactive' sub-periods
    TwoStep training also mentioned in : DuanFinkXie
    
  Start with contiguous 15s periods
    Later do overlapping 15s periods, starting at 1sec (or 3 sec. etc) offsets

  It is likely that the build-up to a seizure involves a stereotypic evolution of such assemblies [4], and if this is the case, a good clustering algorithm combined with a good classification algorithm should offer excellent seizure prediction performance. A literature search reveals that, to the best of our knowledge, no one has previously applied electrode clustering in conjunction with machine learning techniques to seizure prediction.
  
15sec periods map to : (i.e. from 400*16*15 floats)
  Access to original {sd, log(sd), max, log(max)}
  Normalize arrays
  FFT 0 - 48 (or so), complex variables  
  (SAVED)  (i.e. (4+48*2)*16 floats)
  NN field has access to (4+48*2)*16 variables (simple) = 1600
  NN also has entries that calculate upper triangle of Xi(f=a)Xj(f=b)   16*48*16*48/2  = 300k
  This maps to 200(?) hidden units = 300k*200 = 60M weights

Next stage is 200(+200sig~b)->20
Final stage is 20(+20sig~b)->2


SpatiotemporalPrediction-2012_1-s2.0-S1525505012004763-main.pdf
  Indicates that pair-wise correlations, including time-delayed samples, worked.
  Odd sorted eigenvectors idea
  SVM trained 
    Blocks of 15s and 30s work better than 7.5s
    More delay scales work better (3 or more)
    PCA components peak at ~20
    Covariance features not very helpful
    Typical cortial propagation times are O(0.5s)
  
LeCun method
  Dataset available
  Has filter details : 0.5 - 120Hz range, 50Hz notch-out
  Formed various patterns on 5sec of data, then formed NN input from patterns over whole period
    5min pattern length better than 1min
    Cross-correlations had time shifts of +/- 0.5sec
    
Dog Seizures
  Humans may have interesting activity up to 1000Hz
  Dogs <150Hz

PreviousComp
  ExtraTreesClassifier often used
  
EEG-for-Py
  http://nipy.org/nitime/api/generated/nitime.analysis.coherence.html
  

  

## ROC AUC analysis/issues : 
https://www.kaggle.com/c/seizure-prediction/forums/t/10383/leaderboard-metric-roc-auc

I get a huge discrepancy between CV results and leaderboard score. I think that could be due to a higher percentage of positive examples in the test set for Patients 1 and 2. Because these subjects are (by far) the most difficult ones, the gap could be there.

Michael Hills :
There are many different ways you can split the sequence groups, the current split I am using gives me good scores for Dog_2, Dog_3, Dog_5, Patient_1, and bad splits for Dog_1 and Patient_2. Where good is > 0.8 and bad is like < 0.5. Not sure why I'm getting scores less than 0.5 ROC AUC (as low as 0.153), suggesting maybe my features have no useful data? Or at least suggesting that some sequences are quite different to others.



git commit -a -m "Started AES" | grep -v \\.\\.
 
MatPlotLib docs p124 :
You can embed matplotlib into pygtk, wx, Tk, FLTK, or Qt applications. Here is a screenshot of an EEG
viewer called pbrain, which is part of the NeuroImaging in Python suite NIPY.




1	—	Michael Hills *	
0.83403
177	Thu, 16 Oct 2014 03:37:18 (-0.3h)

2	↑2	Tsakalis Kostas *	
0.81576
170	Wed, 15 Oct 2014 19:56:52 (-2.5d)

3	↓1	zzspar *	
0.80999
90	Sat, 11 Oct 2014 09:00:07 (-5.3d)

4	↓1	Dietmar Baum	
0.80878
139	Wed, 15 Oct 2014 23:15:14

5	↑155	Fission	
0.79516
36	Wed, 15 Oct 2014 08:31:40 (-4.8d)

6	↑5	Carlos Fernandez	
0.77988
87	Tue, 14 Oct 2014 19:50:12

7	↓2	Vilen Jumutc	
0.77949
182	Wed, 15 Oct 2014 08:50:46 (-25.4h)

8	↑11	Balu Krishnan	
0.77580
33	Wed, 15 Oct 2014 22:16:38

9	↓2	cgp & Alexandre & blaine  Team	
0.77122
169	Wed, 15 Oct 2014 15:05:01 (-29.5h)

http://www.sharp.co.jp/aquos/products/lc46xl10_spec.html


Hey everyone, I've posted up my documentation and code in another thread, but I thought I'd post here as well as I also wanted to give my answer on the question of how did people handle the size of the data with respect to computational speed etc.

For feature selection I used FFT 1-47Hz, concatenated with correlation coefficients (and their eigenvalues) of both the FFT output data, as well as the input time data. The data was then trained on per-patient Random Forest classifiers (3000 trees).

My background is Computer Engineering, so I spent a lot of time optimising my development cycle to be fast. As an example using 4-cores I can do a cross-validation run against all patients on a 150-tree Random Forest using FFT 1-47Hz in under 4 minutes. The processed data is also cached for re-use if I wanted to try another classifier on it. You can check out my code in the other thread, but to summarise the techniques that I used to streamline the code:

Process each piece of training data as it comes in rather than loading it all and transforming all of it at once. This keeps memory usage down. Before doing this I used to crash my laptop a LOT even with 16GB of RAM.
Cache all processed data to save recomputing it again later
For python numpy arrays use hickle (h5py) instead of pickle, loads most data in 0 seconds
Never hold in memory data you don't need, e.g. for making predictions, first load training data to train the classifier, then drop that data and load the test data for classification. Loading data from hickle format is fast enough that you can forget about load times
Dump scores to disk so I can re-run previous runs to get immediate scoring output if I forgot to copy and paste it out
Can specify lists of different data pipelines to try and lists of classifiers to try. The code would run all combinations and print out the cross-validation scores in sorted order at the end. Additionally if I decided to cancel a run, I could run it again from roughly where it left off as any intermediate results were already cached to disk.
For final classification though I would use 3000 estimators in my Random Forest which blew out run times to 2-3 hours.

Having a fast SSD is also a huge benefit.

